{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba8e3470",
   "metadata": {},
   "source": [
    "# Text classification with naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f9da1e",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4739c55a",
   "metadata": {},
   "source": [
    "Welcome to an amazing project that dives into the naive Bayes classifiers ability to determine what group a chunk of text belongs to based on previous large data sets. In this project, the two sets of data that the Bayes classifer will be working with are one that is 25,000 movie reviews that are positive or negative and the transcript from the presidential debate from September of 2016. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80028337",
   "metadata": {},
   "source": [
    "The Bayes Theorem looks like $$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$$ and for those of you who haven't taken a probability course, the theorem finds that likelihood of A happening given that B has also occurred. For exmaple, the classifier could be used to find probabilities like the odds that it is thundering given that it's also raining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3764a80",
   "metadata": {},
   "source": [
    "The naive Bayes classifer for this project works by taking in a sample string that most likely has something to do with the rest of the dataset. After that string is cleaned up and broken up into a list of individual words, it can go through each of the words and start keeping track of sums of probabilities of where each word was most likely to come from. In the end, you will have a number of sums based on how complex the dataset was and the least negative sum will be where it classifies the phrase from. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830ef52d",
   "metadata": {},
   "source": [
    "For the first part of this project, I will use the Bayes classifier on the transcript from the 2016 debate between Clinton, Trump and Holt, the mediator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84211b2c",
   "metadata": {},
   "source": [
    "### Import Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97691ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807258cb",
   "metadata": {},
   "source": [
    "In these texts, a lot of words are used. Among those words are a lot of words who's purpose are to make communication doable. These words are called stopwords and they are words like \"a\" and \"the.\" These words are important so that we dont sound like cavemen but they arent actually necessary for getting your point across. Throughout this project, I will see the difference in the classifiers outputs when there words are included and ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bfebce5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a,able,about,across,after,all,almost,also,am,among,an,and,any,are,as,at,be,because,been,but,by\n"
     ]
    }
   ],
   "source": [
    "with open('stopwords.txt') as f:\n",
    "    stop_words = f.read()\n",
    "    \n",
    "print(stop_words[:94])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53843d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(review): # method to clean up strings and split them into lists of words\n",
    "    nonochars = ['<br','.',',',';','(',')',':','!','?','/>','\"']\n",
    "    for nono in nonochars:\n",
    "        review = review.replace(nono,'')\n",
    "    review = review.replace('-','').replace('  ',' ')\n",
    "    review = review.lower().split()\n",
    "    return review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf8a4cf",
   "metadata": {},
   "source": [
    "# Presidential Debates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd83387",
   "metadata": {},
   "source": [
    "For this part of the project, I will apply the Bayes classifier to the presidential debate transcript from 2016. Here I will input a sample phrase into the method and it will return which speaker was most likely to say that phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aec14d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Holt</th>\n",
       "      <th>Clinton</th>\n",
       "      <th>Trump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>96.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>80.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>257.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>44.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>289.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>22.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>15.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>39.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>we</th>\n",
       "      <td>22.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>25.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>24.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>have</th>\n",
       "      <td>27.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>147.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Holt  Clinton  Trump\n",
       "the   96.0    253.0  295.0\n",
       "to    80.0    239.0  257.0\n",
       "and   44.0    206.0  289.0\n",
       "that  22.0    147.0  168.0\n",
       "i     15.0    141.0  238.0\n",
       "of    39.0    135.0  171.0\n",
       "we    22.0    131.0  126.0\n",
       "a     25.0    121.0  171.0\n",
       "in    24.0    103.0  110.0\n",
       "have  27.0     84.0  147.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_file = 'debate_transcripts/6_September 26, 2016 Debate Transcript.html'\n",
    "\n",
    "# open up the html file and use BeautifulSoup to make the string easy to work with\n",
    "with open(transcript_file, encoding=\"utf8\") as fp:\n",
    "    soup = BeautifulSoup(fp, 'html.parser')\n",
    "s = soup.text\n",
    "\n",
    "# lists of punctuation and audience words that we want to ignore\n",
    "punc = ',.;:!?\"'\n",
    "otherbadwords = ['--','[applause]','[inaudible]','[laughter]','[crosstalk]']\n",
    "\n",
    "# loop through the punctuation you want to ignore and replace them with nothing\n",
    "for p in punc: \n",
    "    s = s.replace(p,'')\n",
    "    \n",
    "# replace dashes with spaces\n",
    "s = s.replace('—',' ')\n",
    "\n",
    "# removes the que words from the string s\n",
    "for w in otherbadwords: \n",
    "    s = s.replace(w,'')\n",
    "    \n",
    "speakers = ['HOLT','CLINTON','TRUMP']\n",
    "\n",
    "# adds colons after a person starts talk so it is easily identified\n",
    "for sp in speakers: \n",
    "    s = s.replace(sp,sp+':')  \n",
    "\n",
    "tags = [ sp.lower()+':' for sp in speakers ]\n",
    "\n",
    "s = s.lower()\n",
    "\n",
    "# break the transcript up into a list of clean and lowercase words\n",
    "words = s.split()\n",
    "words = words[35:]\n",
    "\n",
    "holts_words = [] # holt list of words\n",
    "clintons_words = [] # clinton list of words\n",
    "trumps_words = [] # trump list of words\n",
    "\n",
    "# based on what the last tag was, adds each word to the list of the last speaker\n",
    "for w in words: \n",
    "    if w == tags[0]: #speaker is Holt\n",
    "        current_speaker = holts_words\n",
    "    elif w == tags[1]: #speaker is Clinton\n",
    "        current_speaker = clintons_words\n",
    "    elif w == tags[2]: #speaker is Trump\n",
    "        current_speaker = trumps_words\n",
    "        \n",
    "    else:\n",
    "        current_speaker.append(w)\n",
    "\n",
    "# counts the number of words each speaker said and puts them into a dictionary        \n",
    "c_holt = Counter(holts_words)\n",
    "c_clinton = Counter(clintons_words)\n",
    "c_trump = Counter(trumps_words)\n",
    "\n",
    "# take the three dictionaries and turn them into a DataFrame\n",
    "d = {'Holt': c_holt, 'Clinton': c_clinton, 'Trump': c_trump}\n",
    "\n",
    "# create the DataFrame\n",
    "df_debate = pd.DataFrame(d)\n",
    "\n",
    "# replaces instances of NaN with 0\n",
    "df_debate = df_debate.fillna(0)\n",
    "\n",
    "# sort the DataFrame by the frequency of the words\n",
    "df_debate = df_debate.sort_values(by=['Clinton','Trump'],ascending = False)\n",
    "df_debate[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb89cd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "september 26 2016 debate transcript\n",
      "presidential debate at hofstra university in hempstead new york\n",
      "september 26 2016\n",
      "participants\n",
      "former secretary of state hillary clinton (d) and\n",
      "businessman donald trump (r)\n",
      "moderator\n",
      "lester holt (nbc news)\n",
      "holt: good evening from hofstra university in hempstead new york i’m lester holt anchor of “nbc nightly news” i want to welcome you to the first presidential debate\n",
      "the participants tonight are donald trump and hillary clinton this debate is sponsored by the commission on presidential debates a nonpartisan nonprofit organization the commission drafted to\n"
     ]
    }
   ],
   "source": [
    "print(s[:600]) # what the first 600 characters of the transcript look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b093dd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = df_debate + 1 # add 1 to all values in the DataFrame to avoid divide by 0 errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da4ca731",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(dc.index.values) # create a list of one of each of the words spoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af55cd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deb_probs(phrase):\n",
    "    \n",
    "    # use the cleaner method to clean up the phrase you want to analyze\n",
    "    phrase  = cleaner(phrase)\n",
    "    \n",
    "    # total number of words in the dataframe\n",
    "    tot = np.array(dc.sum()).sum()\n",
    "     \n",
    "    # fills the prod array with the percent of each speakers words spoken out off all of them    \n",
    "    prod = np.ones(3)\n",
    "    prod[0] = dc['Holt'].sum()/(tot)\n",
    "    prod[1] = dc['Clinton'].sum()/(tot)\n",
    "    prod[2] = dc['Trump'].sum()/(tot)\n",
    "    \n",
    "    # take the log of prod to simplify the numbers worked with\n",
    "    prod = np.log10(prod)\n",
    "\n",
    "    # loop through the words in the input phrase\n",
    "    for word in phrase:\n",
    "        \n",
    "        # makes the word lowercase and then adds the probablility it came from each of the speakers to prod\n",
    "        word = word.lower()\n",
    "        if word not in stop_words:\n",
    "            if word in words:\n",
    "                w = dc.loc[word]\n",
    "                p = w/dc.sum()\n",
    "\n",
    "                prod += np.log10(np.array(p))    \n",
    "    \n",
    "    print(prod)\n",
    "    \n",
    "    # returns the string of the most likely person who said the phrase, based on the least negative probability\n",
    "    return ['Holt','Clinton','Trump'][np.argmax(prod)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51097a5c",
   "metadata": {},
   "source": [
    "To test if the classifer is working, I copied the opening statement from Holt to see if the classifier can confirm that Holt said it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35067537",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-120.60631291 -142.63831965 -146.30524956]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Holt'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase = \"good evening from hofstra university in hempstead new york i’m lester holt anchor of “nbc nightly news” i want to welcome you to the first presidential debate the participants tonight are donald trump and hillary clinton this debate is sponsored by the commission on presidential debates a nonpartisan nonprofit organization the commission drafted tonight’s format and the rules have been agreed to by the campaigns\"\n",
    "deb_probs(phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b28436",
   "metadata": {},
   "source": [
    "As you can see, the least negative product was the first one in the array, which is the product that lines up with Holt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51188a85",
   "metadata": {},
   "source": [
    "Now that it seems like the classifer works, you can create your own phrases and see who the classifier would say that phrase. The first thing I wanted to try was \"Make America Great Again\" as that is Trumps signature slogan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0059195b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-14.35378878 -12.60623401 -13.39703798]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Clinton'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase = \"Make America Great Again\"\n",
    "deb_probs(phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b839449",
   "metadata": {},
   "source": [
    "You would think that the classifier would output Trump but the classifier works by going word by word so Clinton must have said the individual words more than Trump did. Another phrase I was curious about was \"I hate America. Do not vote me for president\" to see what it would classify the opposite of what you want to say at a presidential debate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6779524a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-10.12477284  -9.99597476 -10.8922474 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Clinton'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase = \"I hate America. Do not vote me for president\"\n",
    "deb_probs(phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78daac1",
   "metadata": {},
   "source": [
    "Interestingly, it classified that as something that Clinton would say which perfectly explains why she ended up losing the election to Trump. Now by taking out the conditional statement with the stopwords, you can see the difference when you include the stopwords when classifying "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "130dec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deb_probs_with_stopwords(phrase):\n",
    "    \n",
    "    # use the cleaner method to clean up the phrase you want to analyze\n",
    "    phrase  = cleaner(phrase)\n",
    "    \n",
    "    # total number of words in the dataframe\n",
    "    tot = np.array(dc.sum()).sum()\n",
    "     \n",
    "    # fills the prod array with the percent of each speakers words spoken out off all of them    \n",
    "    prod = np.ones(3)\n",
    "    prod[0] = dc['Holt'].sum()/(tot)\n",
    "    prod[1] = dc['Clinton'].sum()/(tot)\n",
    "    prod[2] = dc['Trump'].sum()/(tot)\n",
    "    \n",
    "    # take the log of prod to simplify the numbers worked with\n",
    "    prod = np.log10(prod)\n",
    "\n",
    "    # loop through the words in the input phrase\n",
    "    for word in phrase:\n",
    "        \n",
    "        # makes the word lowercase and then adds the probablility it came from each of the speakers to prod\n",
    "        word = word.lower()\n",
    "        if word in words:\n",
    "            w = dc.loc[word]\n",
    "            p = w/dc.sum()\n",
    "\n",
    "            prod += np.log10(np.array(p))    \n",
    "    \n",
    "    print(prod)\n",
    "    \n",
    "    # returns the string of the most likely person who said the phrase, based on the least negative probability\n",
    "    return ['Holt','Clinton','Trump'][np.argmax(prod)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b5bb76",
   "metadata": {},
   "source": [
    "Now we can check the three previous phrases and see if the results vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e8ec359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-175.4875487  -193.90588002 -196.61046519]\n",
      "Holt\n",
      "[-14.35378878 -12.60623401 -13.39703798]\n",
      "Clinton\n",
      "[-14.35378878 -12.60623401 -13.39703798]\n",
      "Clinton\n"
     ]
    }
   ],
   "source": [
    "phrase = \"good evening from hofstra university in hempstead new york i’m lester holt anchor of “nbc nightly news” i want to welcome you to the first presidential debate the participants tonight are donald trump and hillary clinton this debate is sponsored by the commission on presidential debates a nonpartisan nonprofit organization the commission drafted tonight’s format and the rules have been agreed to by the campaigns\"\n",
    "print(deb_probs_with_stopwords(phrase))\n",
    "phrase = \"Make America Great Again\"\n",
    "print(deb_probs(phrase))\n",
    "phrase = \"Make America Great Again\"\n",
    "print(deb_probs(phrase))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a6617f",
   "metadata": {},
   "source": [
    "The results are the same when including the stopwords so but this may be because I was only looking at a single transcript. These results coud have been different if you were to look at the transcripts from the last 50 or so years. I would also like to add how the most common words spokes are all about the first person because they are responding to quesitons about themselves, but, one of the most common words is \"we\" because they are always talking about America as a nation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "505ca0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Holt</th>\n",
       "      <th>Clinton</th>\n",
       "      <th>Trump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>96.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>80.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>257.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>44.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>289.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>22.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>15.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>39.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>we</th>\n",
       "      <td>22.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>25.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>24.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>have</th>\n",
       "      <td>27.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>147.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Holt  Clinton  Trump\n",
       "the   96.0    253.0  295.0\n",
       "to    80.0    239.0  257.0\n",
       "and   44.0    206.0  289.0\n",
       "that  22.0    147.0  168.0\n",
       "i     15.0    141.0  238.0\n",
       "of    39.0    135.0  171.0\n",
       "we    22.0    131.0  126.0\n",
       "a     25.0    121.0  171.0\n",
       "in    24.0    103.0  110.0\n",
       "have  27.0     84.0  147.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_debate.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1a4c27",
   "metadata": {},
   "source": [
    "### Movie Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd44e31",
   "metadata": {},
   "source": [
    "Now I will apply the Bayes classifier to a list of 25,000 movie reviews. Here I will loop through each of the reviews and see the accuracy of the classifier and also make up my own mini-reviews that are examples of what would throw off the classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c07ff544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This film is absolutely awful, but nevertheles...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well since seeing part's 1 through 3 I can hon...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I got to see this film at a preview and was da...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This adaptation positively butchers a classic ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Råzone is an awful movie! It is so simple. It ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  This film is absolutely awful, but nevertheles...  negative\n",
       "1  Well since seeing part's 1 through 3 I can hon...  negative\n",
       "2  I got to see this film at a preview and was da...  positive\n",
       "3  This adaptation positively butchers a classic ...  negative\n",
       "4  Råzone is an awful movie! It is so simple. It ...  negative"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv(\"movie_reviews.zip\") # extract the dataframe of movie reviews from the zip file\n",
    "movies[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdc19ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 24750/24750 [02:46<00:00, 148.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>160622.0</td>\n",
       "      <td>170128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>72816.0</td>\n",
       "      <td>87905.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>78039.0</td>\n",
       "      <td>82217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>68092.0</td>\n",
       "      <td>75898.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>68035.0</td>\n",
       "      <td>65828.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eastcoast</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leathermen</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tapers</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'torched'</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>impressivealthough</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122144 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    negative  positive\n",
       "the                 160622.0  170128.0\n",
       "and                  72816.0   87905.0\n",
       "a                    78039.0   82217.0\n",
       "of                   68092.0   75898.0\n",
       "to                   68035.0   65828.0\n",
       "...                      ...       ...\n",
       "eastcoast                1.0       0.0\n",
       "leathermen               1.0       0.0\n",
       "tapers                   1.0       0.0\n",
       "'torched'                1.0       0.0\n",
       "impressivealthough       1.0       0.0\n",
       "\n",
       "[122144 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(movies['review'], \n",
    "                                                    movies['sentiment'], \n",
    "                                                    test_size=0.01, \n",
    "                                                    random_state=1)\n",
    "# create empty strings that for the negative and positive reviews\n",
    "big_string_neg = ''\n",
    "big_string_pos = ''\n",
    "\n",
    "# loop through the list of movie reviews\n",
    "for x in tqdm(range(len(X_train))):\n",
    "    \n",
    "    # if the current review is negative, append the review followed by a space\n",
    "    if movies.iloc[x,1] == 'negative':\n",
    "        big_string_neg += movies.iloc[x,0]\n",
    "        big_string_neg += ' '\n",
    "    else:\n",
    "        \n",
    "    # same process but for positive reviews\n",
    "        big_string_pos += movies.iloc[x,0]\n",
    "        big_string_pos += ' '\n",
    "        \n",
    "# clean up the large strings with the cleaner method\n",
    "big_string_neg = cleaner(big_string_neg)\n",
    "big_string_pos = cleaner(big_string_pos)\n",
    "\n",
    "# apply the counters on both of the big strings for dictionaries of word counts\n",
    "c_n = Counter(big_string_neg)\n",
    "c_p = Counter(big_string_pos)\n",
    "\n",
    "# turn the counters into a dictionary of dictionaries\n",
    "d = {'negative':c_n,'positive':c_p}\n",
    "\n",
    "# turn the dictionary d in to dataframe df\n",
    "df = pd.DataFrame(d)\n",
    "\n",
    "# replace any instance of NaN with 0\n",
    "df = df.fillna(0)\n",
    "\n",
    "df.sort_values(by=['positive','negative'],ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1a9ed96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 2500/2500 [00:01<00:00, 1573.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>16251.0</td>\n",
       "      <td>16806.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>7579.0</td>\n",
       "      <td>8704.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>7865.0</td>\n",
       "      <td>8219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>6913.0</td>\n",
       "      <td>7504.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>6805.0</td>\n",
       "      <td>6590.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reputations</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arabella</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cinderella'</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experimentalism</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unconventionality</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34794 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   negative  positive\n",
       "the                 16251.0   16806.0\n",
       "and                  7579.0    8704.0\n",
       "a                    7865.0    8219.0\n",
       "of                   6913.0    7504.0\n",
       "to                   6805.0    6590.0\n",
       "...                     ...       ...\n",
       "reputations             1.0       0.0\n",
       "arabella               1.0       0.0\n",
       "cinderella'             1.0       0.0\n",
       "experimentalism         1.0       0.0\n",
       "unconventionality       1.0       0.0\n",
       "\n",
       "[34794 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(movies['review'], \n",
    "                                                    movies['sentiment'], \n",
    "                                                    test_size=0.9, \n",
    "                                                    random_state=1)\n",
    "# create empty strings that for the negative and positive reviews\n",
    "big_string_neg_small = ''\n",
    "big_string_pos_small = ''\n",
    "\n",
    "# loop through the list of movie reviews\n",
    "for x in tqdm(range(len(X_train))):\n",
    "    \n",
    "    # if the current review is negative, append the review followed by a space\n",
    "    if movies.iloc[x,1] == 'negative':\n",
    "        big_string_neg_small += movies.iloc[x,0]\n",
    "        big_string_neg_small += ' '\n",
    "    else:\n",
    "        \n",
    "    # same process but for positive reviews\n",
    "        big_string_pos_small += movies.iloc[x,0]\n",
    "        big_string_pos_small += ' '\n",
    "        \n",
    "# clean up the large strings with the cleaner method\n",
    "big_string_neg_small = cleaner(big_string_neg_small)\n",
    "big_string_pos_small = cleaner(big_string_pos_small)\n",
    "\n",
    "# apply the counters on both of the big strings for dictionaries of word counts\n",
    "c_n_small = Counter(big_string_neg_small)\n",
    "c_p_small = Counter(big_string_pos_small)\n",
    "\n",
    "# turn the counters into a dictionary of dictionaries\n",
    "d_small = {'negative':c_n_small,'positive':c_p_small}\n",
    "\n",
    "# turn the dictionary d in to dataframe df\n",
    "df_small = pd.DataFrame(d_small)\n",
    "\n",
    "# replace any instance of NaN with 0\n",
    "df_small = df_small.fillna(0)\n",
    "\n",
    "df_small.sort_values(by=['positive','negative'],ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "185a8871",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = df + 1 # add 1 to each value to avoid divide by 0 errors\n",
    "wc_small = df_small + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2947e613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rev_probs(review): # determines if the input string is either a negative or a positive review\n",
    "    \n",
    "    # clean up the input review\n",
    "    review  = cleaner(review)\n",
    "    \n",
    "    # assign tot to the total number of words\n",
    "    tot = np.array(wc.sum()).sum()\n",
    "    \n",
    "    # fills the prod array with the percent of each speakers words spoken out off all of them    \n",
    "    prod = np.ones(2)\n",
    "    prod[0] = wc['negative'].sum()/(tot)\n",
    "    prod[1] = wc['positive'].sum()/(tot)\n",
    "    \n",
    "    # take the log base 10 of each value in prod\n",
    "    prod = np.log10(prod)\n",
    "    \n",
    "    \n",
    "    for word in review:\n",
    "\n",
    "        # makes each word lowercase and adds the probability it came from a negative or positive review\n",
    "        word = word.lower()\n",
    "        if word not in stop_words:\n",
    "            w = wc.loc[word]\n",
    "            p = w/wc.sum()\n",
    "\n",
    "            prod += np.log10(np.array(p))\n",
    "    #print(prod)\n",
    "    \n",
    "    return ['negative','positive'][np.argmax(prod)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26a68838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rev_probs_small(review): # determines if the input string is either a negative or a positive review\n",
    "    \n",
    "    # clean up the input review\n",
    "    review  = cleaner(review)\n",
    "    \n",
    "    # assign tot to the total number of words\n",
    "    tot = np.array(wc_small.sum()).sum()\n",
    "    \n",
    "    # fills the prod array with the percent of each speakers words spoken out off all of them    \n",
    "    prod = np.ones(2)\n",
    "    prod[0] = wc_small['negative'].sum()/(tot)\n",
    "    prod[1] = wc_small['positive'].sum()/(tot)\n",
    "    \n",
    "    # take the log base 10 of each value in prod\n",
    "    prod = np.log10(prod)\n",
    "    \n",
    "    \n",
    "    for word in review:\n",
    "\n",
    "        # makes each word lowercase and adds the probability it came from a negative or positive review\n",
    "        word = word.lower()\n",
    "        if word not in stop_words:\n",
    "            w = wc_small.loc[word]\n",
    "            p = w/wc_small.sum()\n",
    "\n",
    "            prod += np.log10(np.array(p))\n",
    "    #print(prod)\n",
    "    \n",
    "    return ['negative','positive'][np.argmax(prod)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "380eeac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rev_probs_no_stopwords(review): # determines if the input string is either a negative or a positive review\n",
    "    \n",
    "    # clean up the input review\n",
    "    review  = cleaner(review)\n",
    "    \n",
    "    # assign tot to the total number of words\n",
    "    tot = np.array(wc.sum()).sum()\n",
    "    \n",
    "    # fills the prod array with the percent of each speakers words spoken out off all of them    \n",
    "    prod = np.ones(2)\n",
    "    prod[0] = wc['negative'].sum()/(tot)\n",
    "    prod[1] = wc['positive'].sum()/(tot)\n",
    "    \n",
    "    # take the log base 10 of each value in prod\n",
    "    prod = np.log10(prod)\n",
    "    \n",
    "    \n",
    "    for word in review:\n",
    "\n",
    "        # makes each word lowercase and adds the probability it came from a negative or positive review\n",
    "        word = word.lower()\n",
    "        w = wc.loc[word]\n",
    "        p = w/wc.sum()\n",
    "\n",
    "        prod += np.log10(np.array(p))\n",
    "    #print(prod)\n",
    "    \n",
    "    return ['negative','positive'][np.argmax(prod)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6047b3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"\"\"I saw this recent Woody Allen film because I\\'m a fan of\n",
    "his work and I make it a point to try to see everything he does, though\n",
    "the reviews of this film led me to expect a disappointing effort. They were right.\n",
    "This is a confused movie that can\\'t decide whether it wants to be a comedy,\n",
    "a romantic fantasy, or a drama about female mid-life crisis. It fails at all three.\n",
    "<br /><br />Alice (Mia Farrow) is a restless middle aged woman who has married into\n",
    "great wealth and leads a life of aimless luxury with her rather boring husband and\n",
    "their two small children. This rather mundane plot concept is livened up with such\n",
    "implausibilities as an old Chinese folk healer who makes her invisible with some magic\n",
    "herbs, and the ghost of a former lover (with whom she flies over Manhattan). If these\n",
    "additions sound too fantastic for you, how about something more prosaic, like an affair\n",
    "with a saxophone player?<br /><br />I was never quite sure of what this mixed up muddle\n",
    "was trying to say. There are only a handful of truly funny moments in the film,\n",
    "and the endingis a really preposterous touch of Pollyanna.<br /><br />Rent \\'Crimes and\n",
    "Misdemeanors\\' instead, a superbly well-done film that suceeds in combining comedy with\n",
    "a serious consideration of ethics and morals. Or go back to \"Annie Hall\" or \"Manhattan\".\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9590e744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n"
     ]
    }
   ],
   "source": [
    "#prod = rev_probs(movies.iloc[3,0])\n",
    "prod = rev_probs(review)\n",
    "\n",
    "print(prod)\n",
    "#print(['negative','positive'][np.argmax(prod)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a33c367",
   "metadata": {},
   "source": [
    "Now that I tested that the classifer works with this sample negative review of Annie, I ca  start analyzing the performance of the classifier. The first statistic I wanted to look at is the accuracy of the classifer. By adding up the total number of reviews classified correctly divided by the number of reviews you can get the accuracy. This a slow process so I will get a rough estimate from the first 100 comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79435ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 100/100 [00:28<00:00,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "den = 100\n",
    "for x in tqdm(range(100)):\n",
    "    estimate = rev_probs(movies.iloc[x,0])\n",
    "    if estimate == movies.iloc[x,1]:\n",
    "        num += 1\n",
    "print(num/den)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "422b3912",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 100/100 [00:43<00:00,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "den = 100\n",
    "for x in tqdm(range(100)):\n",
    "    estimate = rev_probs_no_stopwords(movies.iloc[x,0])\n",
    "    if estimate == movies.iloc[x,1]:\n",
    "        num += 1\n",
    "print(num/den)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4186d26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 100/100 [00:14<00:00,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "den = 100\n",
    "for x in tqdm(range(100)):\n",
    "    estimate = rev_probs_small(movies.iloc[x,0])\n",
    "    if estimate == movies.iloc[x,1]:\n",
    "        num += 1\n",
    "print(num/den)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b72531",
   "metadata": {},
   "source": [
    "This means that in the first 100 reviews, the classifer had a 93% accuracy. When testing the first 100 reviews with a smaller training set the accuracy went from 93 to 99%. Below is an example of a misclassified review: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41c65a68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This adaptation positively butchers a classic which is beloved for its subtlety. Timothy Dalton has absolutely no conception of the different nuances of Rochester's character. I get the feeling he never even read the book, just sauntered on set in his too tight breeches and was handed a character summary that read \"Grumpy, broody, murky past.\" He plays Rochester not as a character or as a real person but as an over the top grouch who never cracks a smile until after he gets engaged at which point he miraculously morphs into a pansy. There is no chemistry. The only feeling that this adaptation excited in me was incredulity and also sympathy for Charlotte Bronte who is most definitely turning in her grave. GO AND REREAD THE BOOK. ROCHESTER HAS A PERSONALITY. AND BY THE WAY: A \"PASSIONATE\" LOVE SCENE DOES NOT MEAN YOU HAVE TO EAT HER FACE.\n",
      "\n",
      "This review is negative\n",
      "But it was classified as positive\n"
     ]
    }
   ],
   "source": [
    "print(movies.iloc[3,0])\n",
    "print()\n",
    "print(\"This review is \" + movies.iloc[3,1])\n",
    "print(\"But it was classified as \" + rev_probs(movies.iloc[3,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ee0612",
   "metadata": {},
   "source": [
    "When reading this review I understand why it was missclassified. The Database says that this is a negative review but the classifier says that it is positive. When reading it there are a lot of words that point to it being a positive review. Words like \"smile\" and \"positively\" are words that I would associate with a positive review but are used in this negative one. When testing the same misclassified review with a classifier that used a larger training set you get these results with that review:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bacbd745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This review is negative\n",
      "But it was classified as negative\n"
     ]
    }
   ],
   "source": [
    "print(\"This review is \" + movies.iloc[3,1])\n",
    "print(\"But it was classified as \" + rev_probs_small(movies.iloc[3,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072b1253",
   "metadata": {},
   "source": [
    "Now with the larger training set, the classifier is more accurate. The classifier with the smaller training set has the same effect as if I wrote a review saying \"This movie is so poorly written and dumb that it's hilarious.\" This is a positive review that is very liekly to be classified as a negative one because I am using negative words in a positive way. If I put the sample phrase into the classifier, it says that the review is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a86961e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_probs(\"This movie is so poorly written and dumb that it's hilarious\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31ee4a9",
   "metadata": {},
   "source": [
    "As you can see, even though I though this comedy was hilarious it classified it as a negative review. But If I write something as simple as \"This movies was good\" it is expected to be classifed as positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e580dd6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_probs(\"This movie was good\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630e169c",
   "metadata": {},
   "source": [
    "Now this is a suprising result. This is similar to the case where the classifier said that Clinton is more likely to say \"Make America Great Again.\" Because the classifier goes word by word and this review without the stopwords is just \"movie\" and \"good\" you would think it would be positive. So now I want to see what it classifies the word \"movie\" and \"good\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca3b3d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_probs(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e311870a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_probs(\"movie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6abb37",
   "metadata": {},
   "source": [
    "From this I conclude that the probability that good apprears in a positive review is outweighed by movie in a negative review. This just shows that people writing positive reviews like using more descriptive words than \"good.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2e198aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_probs(\"This movie was great\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f658aacf",
   "metadata": {},
   "source": [
    "When changing \"good\" to \"great\" the review is even more positive so it is classified as such"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1c3f41",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eea60f",
   "metadata": {},
   "source": [
    "* The most common words in any set of data will always be the stopwords like \"the\" and \"a\" but when you ignore them they are most specific to the class of data you are looking at\n",
    "* Missclassified texts tend to be because of the way the author uses language. If someone likes to emphasize the positive by using negative words, it trips up the classifer as a computer cannot detect personality. \n",
    "* When I wrote my own sample texts where I thought I would know the classification, it would still sometimes missclassify the text. The sample review \"This movie is good\" was classified as negative even though it is clearly a positive review. This comes down to the fact that the classifier works word by word and some words have higher probabilities of appearing and can tip the weight of the classification.\n",
    "* When using a classifier that used a training set of 90%, I found it to be much more accurate. Out of the first 100 reviews, it only misclassifed a single review vs. the 7 the 1% training set misclassified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf518c4f",
   "metadata": {},
   "source": [
    "## Bibliography/References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d9d3c4",
   "metadata": {},
   "source": [
    "1. Gandhi, R. (2018, May 17). Naive Bayes classifier. Medium. Retrieved April 23, 2023, from https://towardsdatascience.com/naive-bayes-classifier-81d512f50a7c "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
